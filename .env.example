# AI Inference Platform Configuration
# Copy this file to .env and fill in your actual values

# Server Configuration
PORT=3000
NODE_ENV=development

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
# Optional: Fallback API key for failover
OPENAI_API_KEY_FALLBACK=
# Optional: Custom endpoint (e.g., for Azure OpenAI)
OPENAI_ENDPOINT=
OPENAI_ENDPOINT_FALLBACK=

# Anthropic Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key_here
# Optional: Fallback API key for failover
ANTHROPIC_API_KEY_FALLBACK=
# Optional: Custom endpoint
ANTHROPIC_ENDPOINT=
ANTHROPIC_ENDPOINT_FALLBACK=

# OpenRouter Configuration
OPENROUTER_API_KEY=your_openrouter_api_key_here
# Optional: Fallback API key for failover
OPENROUTER_API_KEY_FALLBACK=
# Optional: Custom endpoint
OPENROUTER_ENDPOINT=
OPENROUTER_ENDPOINT_FALLBACK=
# Optional: HTTP referer header (for app tracking)
OPENROUTER_REFERER=
# Optional: Title for your app in OpenRouter
OPENROUTER_TITLE=

# Ollama Configuration (for local models)
# Default: http://localhost:11434
OLLAMA_ENDPOINT=http://localhost:11434
# Optional: Fallback endpoint
OLLAMA_ENDPOINT_FALLBACK=

# Redis Configuration (REQUIRED for collaboration features)
REDIS_URL=redis://localhost:6379
# REQUIRED - Generate a strong password for Redis
REDIS_PASSWORD=your_redis_password_here

# Database Configuration
# SQLite is used by default, no configuration needed
# For production, consider using PostgreSQL:
# DATABASE_URL=postgresql://user:password@localhost:5432/dbname

# Security Configuration
# Generate a secure session secret: openssl rand -hex 32
SESSION_SECRET=your_session_secret_here
# Generate a secure JWT secret: openssl rand -hex 32
JWT_SECRET=your_jwt_secret_here
# CSRF protection secret: openssl rand -hex 32
CSRF_SECRET=your_csrf_secret_here
# Initial admin password (CHANGE THIS IMMEDIATELY after first login!)
INITIAL_ADMIN_PASSWORD=your_secure_password_here

# CORS Configuration (comma-separated list of allowed origins)
CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# Content Security Policy
CSP_DIRECTIVES=default-src 'self'; script-src 'self' 'unsafe-inline' 'unsafe-eval'; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self'; connect-src 'self' ws: wss:;

# Logging Configuration
LOG_LEVEL=info
# Options: error, warn, info, debug

# File Upload Configuration
MAX_FILE_SIZE=10485760
# 10MB in bytes
ALLOWED_FILE_TYPES=.txt,.md,.pdf,.json,.csv

# Rate Limiting Configuration
RATE_LIMIT_WINDOW=900000
# 15 minutes in milliseconds
RATE_LIMIT_MAX_REQUESTS=100
# Maximum requests per window

# MCP (Model Context Protocol) Configuration
MCP_SERVER_TIMEOUT=30000
# Timeout in milliseconds for MCP server responses
MCP_MAX_CONTEXT_SIZE=128000
# Maximum context size in tokens

# Agent Configuration
MAX_AGENTS_PER_WORKSPACE=10
AGENT_TIMEOUT=300000
# Agent response timeout in milliseconds (5 minutes)
DEFAULT_AGENT_MODEL=gpt-4o
DEFAULT_AGENT_TEMPERATURE=1.0
DEFAULT_AGENT_MAX_TOKENS=2048

# Knowledge Base Configuration
KNOWLEDGE_BASE_PATH=./data/knowledge
EMBEDDING_MODEL=text-embedding-ada-002
EMBEDDING_PROVIDER=openai

# Collaboration Engine Configuration
COLLABORATION_MESSAGE_RETENTION=86400000
# 24 hours in milliseconds
MAX_COLLABORATION_HISTORY=1000
# Maximum messages to retain per conversation

# Performance Configuration
ENABLE_RESPONSE_STREAMING=true
ENABLE_CACHING=true
CACHE_TTL=3600
# Cache time-to-live in seconds

# Development Configuration
ENABLE_HOT_RELOAD=true
ENABLE_DEBUG_LOGGING=false
MOCK_AI_RESPONSES=false
# Set to true to use mock responses for testing without API calls
DISABLE_AUTH=false
# Set to true to disable all authentication (for development/testing only)
